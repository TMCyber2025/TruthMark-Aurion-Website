{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b05ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Install required packages\n",
    "!pip install mediapipe deepface librosa matplotlib fpdf pandas opencv-python --quiet\n",
    "!apt-get install -y ffmpeg --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776132a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Set video path (upload your .mov file to the Files tab first)\n",
    "video_path = \"movie_test.mov\"\n",
    "audio_path = \"/mnt/data/audio.wav\"\n",
    "\n",
    "import os, cv2, numpy as np, librosa, matplotlib.pyplot as plt\n",
    "import mediapipe as mp, pandas as pd, shutil\n",
    "from datetime import datetime\n",
    "from deepface import DeepFace\n",
    "from fpdf import FPDF\n",
    "from scipy.signal import find_peaks\n",
    "import subprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d67f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéôÔ∏è Extract audio\n",
    "os.makedirs(\"/mnt/data\", exist_ok=True)\n",
    "subprocess.call(['ffmpeg', '-i', video_path, '-ab', '160k', '-ac', '2', '-ar', '44100', '-vn', audio_path])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9525b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Audio analysis\n",
    "y, sr = librosa.load(audio_path, sr=None)\n",
    "rms = librosa.feature.rms(y=y)[0]\n",
    "rms_std = np.std(rms)\n",
    "pitch, mag = librosa.piptrack(y=y, sr=sr)\n",
    "pitch_values = pitch[mag > np.median(mag)]\n",
    "pitch_std = np.std(pitch_values) if len(pitch_values) > 0 else 0\n",
    "intervals = librosa.effects.split(y, top_db=30)\n",
    "gaps = [(intervals[i][0] - intervals[i-1][1]) / sr for i in range(1, len(intervals))]\n",
    "avg_latency = np.mean(gaps) if gaps else 0\n",
    "cognitive_load = np.var(rms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a9b470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üëÅÔ∏è Blink detection using EAR\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "ear_values = []\n",
    "\n",
    "def calc_ear(landmarks, indices):\n",
    "    try:\n",
    "        p = lambda i: np.array([landmarks[i].x, landmarks[i].y])\n",
    "        vertical = np.linalg.norm(p(indices[1]) - p(indices[5])) + np.linalg.norm(p(indices[2]) - p(indices[4]))\n",
    "        horizontal = 2 * np.linalg.norm(p(indices[0]) - p(indices[3]))\n",
    "        return vertical / horizontal if horizontal != 0 else 0\n",
    "    except: return 0\n",
    "\n",
    "with mp_face_mesh.FaceMesh(static_image_mode=True) as mesh:\n",
    "    for i in range(0, frame_count, max(1, frame_count // 30)):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "        ret, f = cap.read()\n",
    "        if not ret: continue\n",
    "        rgb = cv2.cvtColor(f, cv2.COLOR_BGR2RGB)\n",
    "        result = mesh.process(rgb)\n",
    "        if result.multi_face_landmarks:\n",
    "            lmk = result.multi_face_landmarks[0].landmark\n",
    "            ear = calc_ear(lmk, [33, 160, 158, 133, 153, 144])\n",
    "            ear_values.append(ear)\n",
    "\n",
    "blinks, _ = find_peaks(np.array(ear_values), prominence=0.01)\n",
    "blink_rate = len(blinks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8b4163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üòä Emotion detection\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, frame_count // 2)\n",
    "ret, frame = cap.read()\n",
    "emotion_result = DeepFace.analyze(frame, actions=['emotion'], enforce_detection=False)\n",
    "dominant_emotion = emotion_result[0]['dominant_emotion']\n",
    "emotion_probs = emotion_result[0]['emotion']\n",
    "emotion_chart = list(emotion_probs.items())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d6a911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìà Save graphs\n",
    "def save_graph(func, path):\n",
    "    func()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path)\n",
    "    plt.close()\n",
    "\n",
    "save_graph(lambda: plt.barh([x[0] for x in emotion_chart], [x[1] for x in emotion_chart]), \"emotion_chart.png\")\n",
    "save_graph(lambda: plt.plot(ear_values), \"blink_graph.png\")\n",
    "save_graph(lambda: plt.plot(rms[:300]), \"rms_chart.png\")\n",
    "save_graph(lambda: plt.hist(pitch_values, bins=50), \"pitch_histogram.png\")\n",
    "\n",
    "signal_vals = [pitch_std/800, rms_std/0.2, avg_latency/2, blink_rate/50, cognitive_load/0.1]\n",
    "save_graph(lambda: plt.barh(range(5), signal_vals), \"truthmatch_score.png\")\n",
    "\n",
    "truth_score = round(1 - np.mean(signal_vals), 3)\n",
    "truth_score = min(max(truth_score, 0.0), 1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461a58d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üßæ PDF Report\n",
    "pdf = FPDF()\n",
    "pdf.set_auto_page_break(auto=True, margin=10)\n",
    "pdf.add_page()\n",
    "pdf.set_font(\"Arial\", 'B', 16)\n",
    "pdf.cell(0, 10, \"TruthMark-Aurion Forensic Report\", ln=True)\n",
    "pdf.set_font(\"Arial\", size=12)\n",
    "pdf.cell(0, 10, \"Scan Date: \" + datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"), ln=True)\n",
    "pdf.ln(10)\n",
    "\n",
    "pdf.multi_cell(0, 10, f\"\"\"\n",
    "‚Ä¢ Dominant Emotion: {dominant_emotion}\n",
    "‚Ä¢ Blink Rate: {blink_rate}\n",
    "‚Ä¢ Voice Tremor Std Dev: {pitch_std:.2f} Hz\n",
    "‚Ä¢ Emotion RMS Std Dev: {rms_std:.4f}\n",
    "‚Ä¢ Speech Latency Avg: {avg_latency:.2f} sec\n",
    "‚Ä¢ Cognitive Load Proxy: {cognitive_load:.5f}\n",
    "‚Ä¢ TruthMatch Score: {truth_score:.3f}\n",
    "\"\"\")\n",
    "\n",
    "for graph in [\"emotion_chart.png\", \"blink_graph.png\", \"rms_chart.png\", \"pitch_histogram.png\", \"truthmatch_score.png\"]:\n",
    "    if os.path.exists(graph):\n",
    "        pdf.add_page()\n",
    "        pdf.image(graph, x=10, w=180)\n",
    "\n",
    "pdf.output(\"TruthMark_Aurion_Master_Report.pdf\")\n",
    "print(\"‚úÖ PDF saved as TruthMark_Aurion_Master_Report.pdf\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}